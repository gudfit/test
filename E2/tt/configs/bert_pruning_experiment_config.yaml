experiment_name: "bert_base_pruning_capacity"
base_model_id: "bert-base-uncased" 
dataset_name: "wikitext"
dataset_subset: "wikitext-2-raw-v1"
test_split: "validation"
output_file: "results/bert_pruning_semantic_results.csv"

device: "cuda"

lambda_budgets:
  - name: "BERT-base (0% pruned)"
    path: "models/pruned_bert_base/pruned_0.pt"
  - name: "BERT-base (20% pruned)"
    path: "models/pruned_bert_base/pruned_20.pt"
  - name: "BERT-base (40% pruned)"
    path: "models/pruned_bert_base/pruned_40.pt"
  - name: "BERT-base (60% pruned)"
    path: "models/pruned_bert_base/pruned_60.pt"
  - name: "BERT-base (80% pruned)"
    path: "models/pruned_bert_base/pruned_80.pt"

theta_budgets: [0.1, 0.5 ,0.9]
